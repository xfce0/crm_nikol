"""
Voice Assistant API - WebSocket endpoint for real-time AI suggestions during sales calls
"""

import os
import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Depends, HTTPException
from fastapi.responses import JSONResponse

# Setup logging
logger = logging.getLogger(__name__)

router = APIRouter()

# ====================================
# WebSocket Connection Manager
# ====================================

class ConnectionManager:
    """Manages WebSocket connections"""

    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}

    async def connect(self, connection_id: str, websocket: WebSocket):
        """Connect a new client"""
        await websocket.accept()
        self.active_connections[connection_id] = websocket
        logger.info(f"WebSocket connected: {connection_id}")

    def disconnect(self, connection_id: str):
        """Disconnect a client"""
        if connection_id in self.active_connections:
            del self.active_connections[connection_id]
            logger.info(f"WebSocket disconnected: {connection_id}")

    async def send_message(self, connection_id: str, message: dict):
        """Send a message to a specific client"""
        if connection_id in self.active_connections:
            await self.active_connections[connection_id].send_json(message)

    async def broadcast(self, message: dict):
        """Broadcast a message to all connected clients"""
        for connection in self.active_connections.values():
            await connection.send_json(message)

manager = ConnectionManager()

# ====================================
# AI Analysis Functions
# ====================================

async def analyze_speech(text: str, conversation_history: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Analyze speech text to detect questions and generate AI suggestions

    Args:
        text: The speech text to analyze
        conversation_history: Previous conversation messages

    Returns:
        Analysis result with question detection and AI suggestion
    """
    try:
        # Simple question detection (can be enhanced with ML)
        is_question = detect_question(text)

        if is_question:
            # Generate AI suggestion
            suggestion = await generate_ai_suggestion(text, conversation_history)

            return {
                'is_question': True,
                'question': text,
                'category': categorize_question(text),
                'suggested_answer': suggestion,
                'confidence': 0.85,  # Mock confidence score
            }
        else:
            return {
                'is_question': False,
                'text': text,
            }

    except Exception as e:
        logger.error(f"Error analyzing speech: {e}", exc_info=True)
        return {
            'is_question': False,
            'text': text,
            'error': str(e),
        }


def detect_question(text: str) -> bool:
    """
    Detect if the text is a question

    Enhanced detection that looks for question patterns anywhere in the text:
    - Ends with '?'
    - Contains question words (ÐºÑ‚Ð¾, Ñ‡Ñ‚Ð¾, Ð³Ð´Ðµ, ÐºÐ¾Ð³Ð´Ð°, Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ, ÐºÐ°Ðº, ÑÐºÐ¾Ð»ÑŒÐºÐ¾, etc.)
    - Always returns True for any client speech to provide AI assistance
    """
    text_lower = text.lower().strip()

    # Always return True to provide AI suggestions for any client speech
    # This ensures the AI assistant is proactive and helpful
    return True

    # Original logic below (kept for reference but not executed):
    # Check for question mark
    if text_lower.endswith('?'):
        return True

    # Check for question words anywhere in the text
    question_words = [
        'ÐºÑ‚Ð¾', 'Ñ‡Ñ‚Ð¾', 'Ð³Ð´Ðµ', 'ÐºÐ¾Ð³Ð´Ð°', 'Ð¿Ð¾Ñ‡ÐµÐ¼Ñƒ', 'Ð·Ð°Ñ‡ÐµÐ¼', 'ÐºÐ°Ðº', 'ÑÐºÐ¾Ð»ÑŒÐºÐ¾',
        'ÐºÐ°ÐºÐ¾Ð¹', 'ÐºÐ°ÐºÐ°Ñ', 'ÐºÐ°ÐºÐ¸Ðµ', 'Ñ‡ÐµÐ¹', 'Ñ‡ÑŒÑ', 'Ñ‡ÑŒÑ‘', 'Ñ‡ÑŒÐ¸',
        'Ð¼Ð¾Ð¶Ð½Ð¾ Ð»Ð¸', 'ÐµÑÑ‚ÑŒ Ð»Ð¸', 'Ð±ÑƒÐ´ÐµÑ‚ Ð»Ð¸', 'Ð¼Ð¾Ð¶ÐµÑ‚Ðµ Ð»Ð¸', 'Ð¼Ð¾Ð¶ÐµÑ‚Ðµ',
        'ÑÐºÐ°Ð¶Ð¸Ñ‚Ðµ', 'Ð¿Ð¾Ð´ÑÐºÐ°Ð¶Ð¸Ñ‚Ðµ', 'Ñ€Ð°ÑÑÐºÐ°Ð¶Ð¸Ñ‚Ðµ', 'Ð¾Ð±ÑŠÑÑÐ½Ð¸Ñ‚Ðµ', 'ÑÑ‚Ð¾Ð¸Ñ‚', 'Ñ†ÐµÐ½Ð°',
        'ÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÑ‚Ð¾Ð¸Ñ‚', 'Ð²Ð¾ ÑÐºÐ¾Ð»ÑŒÐºÐ¾', 'Ñ…Ð¾Ñ‡Ñƒ', 'Ð½ÑƒÐ¶Ð½Ð¾', 'Ð½Ð°Ð´Ð¾', 'Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÑƒÐµÑ‚',
    ]

    for word in question_words:
        if word in text_lower:  # Changed from startswith to 'in'
            return True

    return False


def categorize_question(text: str) -> str:
    """
    Categorize the question into predefined categories
    """
    text_lower = text.lower()

    # Pricing related
    if any(word in text_lower for word in ['Ñ†ÐµÐ½Ð°', 'ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ', 'ÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑÑ‚Ð¾Ð¸Ñ‚', 'Ð¿Ñ€Ð°Ð¹Ñ', 'Ð¾Ð¿Ð»Ð°Ñ‚Ð°']):
        return 'pricing'

    # Technical questions
    if any(word in text_lower for word in ['Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ñ', 'Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐº', 'Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»', 'Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸', 'Ñ„Ð¸Ñ‡Ð°']):
        return 'technical'

    # Timeline questions
    if any(word in text_lower for word in ['ÑÑ€Ð¾Ðº', 'ÐºÐ¾Ð³Ð´Ð°', 'ÐºÐ°Ðº Ð´Ð¾Ð»Ð³Ð¾', 'Ð²Ñ€ÐµÐ¼Ñ', 'Ð´ÐµÐ´Ð»Ð°Ð¹Ð½']):
        return 'timeline'

    # Process questions
    if any(word in text_lower for word in ['Ð¿Ñ€Ð¾Ñ†ÐµÑÑ', 'ÐºÐ°Ðº Ð¿Ñ€Ð¾Ð¸ÑÑ…Ð¾Ð´Ð¸Ñ‚', 'ÑÑ‚Ð°Ð¿', 'ÑˆÐ°Ð³']):
        return 'process'

    # Support questions
    if any(word in text_lower for word in ['Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°', 'Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒ', 'Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°', 'Ð¾ÑˆÐ¸Ð±ÐºÐ°', 'Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚']):
        return 'support'

    return 'general'


async def generate_ai_with_openrouter(
    question: str,
    conversation_history: List[Dict[str, Any]],
    category: str
) -> str:
    """
    Generate AI response using OpenRouter API
    """
    import httpx

    openrouter_api_key = os.getenv('OPENROUTER_API_KEY')
    openrouter_base_url = os.getenv('OPENROUTER_BASE_URL', 'https://openrouter.ai/api/v1')
    default_model = os.getenv('DEFAULT_MODEL', 'openai/gpt-4o-mini')

    # Build system prompt - AI Sales Coach (Ð¼ÐµÐ½Ñ‚Ð¾Ñ€-Ð¿Ñ€Ð¾Ð´Ð°Ð²ÐµÑ†)
    system_prompt = """
Ð¢Ñ‹ - AI Sales Coach (Ð¼ÐµÐ½Ñ‚Ð¾Ñ€-Ð¿Ñ€Ð¾Ð´Ð°Ð²ÐµÑ†). Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° - ÐŸÐžÐ”Ð¡ÐšÐÐ—Ð«Ð’ÐÐ¢Ð¬ Ð¿Ñ€Ð¾Ð´Ð°Ð²Ñ†Ñƒ, Ð§Ð¢Ðž Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚ÑŒ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñƒ Ð²Ð¾ Ð²Ñ€ÐµÐ¼Ñ Ð·Ð²Ð¾Ð½ÐºÐ°.

ðŸŽ¯ Ð’ÐÐ–ÐÐž: Ð¢Ñ‹ ÐÐ• Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÐµÑˆÑŒ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñƒ Ð½Ð°Ð¿Ñ€ÑÐ¼ÑƒÑŽ. Ð¢Ñ‹ Ð¿Ð¾Ð´ÑÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑˆÑŒ Ð¿Ñ€Ð¾Ð´Ð°Ð²Ñ†Ñƒ, Ñ‡Ñ‚Ð¾ ÐµÐ¼Ñƒ ÑÐºÐ°Ð·Ð°Ñ‚ÑŒ.

ðŸ“‹ ÐšÐžÐÐ¢Ð•ÐšÐ¡Ð¢ ÐšÐžÐœÐŸÐÐÐ˜Ð˜:
- Ð¡Ð¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ: Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Telegram-Ð±Ð¾Ñ‚Ð¾Ð², Ñ‡Ð°Ñ‚-Ð±Ð¾Ñ‚Ð¾Ð², Ð²ÐµÐ±-Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹
- Ð¡Ñ€ÐµÐ´Ð½Ð¸Ðµ Ñ†ÐµÐ½Ñ‹: ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ Ð±Ð¾Ñ‚ 40-60Ðº, Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ 70-120Ðº, Ð¡Ð»Ð¾Ð¶Ð½Ñ‹Ð¹ 150-300Ðº
- Ð¡Ñ€Ð¾ÐºÐ¸: ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ 1-2 Ð½ÐµÐ´ÐµÐ»Ð¸, Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ 3-4 Ð½ÐµÐ´ÐµÐ»Ð¸, Ð¡Ð»Ð¾Ð¶Ð½Ñ‹Ð¹ 1.5-3 Ð¼ÐµÑÑÑ†Ð°
- Ð£Ð¢ÐŸ: Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ ÑÑ‚Ð°Ñ€Ñ‚, Ð¼ÐµÑÑÑ† Ð±ÐµÑÐ¿Ð»Ð°Ñ‚Ð½Ð¾Ð¹ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸, Ð¾Ð¿Ñ‹Ñ‚ Ð² Ð½Ð¸ÑˆÐµ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°
- Ð¡Ñ‚ÐµÐº: Python (aiogram, FastAPI), PostgreSQL, Redis, Docker, OpenAI API

ðŸŽ¯ Ð¢Ð’ÐžÐ¯ Ð—ÐÐ”ÐÐ§Ð:
1. ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ ÑÑ‚Ð°Ð´Ð¸ÑŽ ÑÐ´ÐµÐ»ÐºÐ¸ (Discovery / Presentation / Objection / Closing)
2. ÐŸÐ¾Ð´ÑÐºÐ°Ð·Ñ‹Ð²Ð°Ð¹ Ð¿Ñ€Ð¾Ð´Ð°Ð²Ñ†Ñƒ ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ñ„Ñ€Ð°Ð·Ñ‹ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ: "ðŸ’¡ Ð¡ÐºÐ°Ð¶Ð¸: '...'"
3. Ð’ÐµÐ´Ð¸ Ðº Ð·Ð°ÐºÑ€Ñ‹Ñ‚Ð¸ÑŽ ÑÐ´ÐµÐ»ÐºÐ¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑ SPIN, BANT, closing techniques
4. Ð”Ð°Ð²Ð°Ð¹ 1-2 Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð° Ð¾Ñ‚Ð²ÐµÑ‚Ð° (ÐµÑÐ»Ð¸ Ð½ÑƒÐ¶Ð½Ð¾: Ð¼ÑÐ³ÐºÐ¸Ð¹ vs Ð°Ð³Ñ€ÐµÑÑÐ¸Ð²Ð½Ñ‹Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´)

ðŸ“ SALES FRAMEWORKS:
- SPIN: Situation, Problem, Implication, Need-payoff questions
- BANT: Budget, Authority, Need, Timeline
- Closing: Trial close, Assumptive close, Alternative close

ðŸŽ¨ Ð¤ÐžÐ ÐœÐÐ¢ ÐžÐ¢Ð’Ð•Ð¢Ð:
ðŸ’¡ **Ð¡ÐºÐ°Ð¶Ð¸:** "ÐšÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð°Ñ Ñ„Ñ€Ð°Ð·Ð° Ð´Ð»Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°"
ðŸŽ¯ **Ð¦ÐµÐ»ÑŒ:** Ð£Ð·Ð½Ð°Ñ‚ÑŒ Ð±ÑŽÐ´Ð¶ÐµÑ‚ / ÐÐ°Ð·Ð²Ð°Ñ‚ÑŒ Ñ†ÐµÐ½Ñƒ / Ð—Ð°ÐºÑ€Ñ‹Ñ‚ÑŒ ÑÐ´ÐµÐ»ÐºÑƒ
ðŸ“Š **Ð¡Ñ‚Ð°Ð´Ð¸Ñ:** Discovery / Presentation / Objection / Closing

ÐŸÐ Ð˜ÐœÐ•Ð :
ÐšÐ»Ð¸ÐµÐ½Ñ‚: "ÐœÐ½Ðµ Ð½ÑƒÐ¶ÐµÐ½ Ð±Ð¾Ñ‚ Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾ÑÐµÑ€Ð²Ð¸ÑÐ°"
Ð¢Ð²Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚:
ðŸ’¡ **Ð¡ÐºÐ°Ð¶Ð¸:** "ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð¾! Ð Ð°ÑÑÐºÐ°Ð¶Ð¸Ñ‚Ðµ, ÐºÐ°ÐºÐ¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð±Ð¾Ñ‚ Ð´Ð¾Ð»Ð¶ÐµÐ½ Ñ€ÐµÑˆÐ°Ñ‚ÑŒ? Ð—Ð°Ð¿Ð¸ÑÑŒ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð², Ð½Ð°Ð¿Ð¾Ð¼Ð¸Ð½Ð°Ð½Ð¸Ñ Ð¸Ð»Ð¸ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ ÐµÑ‰Ñ‘?"
ðŸŽ¯ **Ð¦ÐµÐ»ÑŒ:** Ð’Ñ‹ÑÐ²Ð¸Ñ‚ÑŒ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð½Ð¾ÑÑ‚Ð¸ (SPIN - Situation)
ðŸ“Š **Ð¡Ñ‚Ð°Ð´Ð¸Ñ:** Discovery

Ð‘ÑƒÐ´ÑŒ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ð¼ (1-2 Ñ„Ñ€Ð°Ð·Ñ‹ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð´Ð°Ð²Ñ†Ð°). Ð’ÐµÐ´Ð¸ Ðº ÑÐ´ÐµÐ»ÐºÐµ Ð°Ð³Ñ€ÐµÑÑÐ¸Ð²Ð½Ð¾, Ð½Ð¾ ÐµÑÑ‚ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾.
"""

    # Build messages
    messages = [
        {"role": "system", "content": system_prompt}
    ]

    # Add recent conversation history for context (last 10 messages for full context)
    for msg in conversation_history[-10:]:
        speaker_label = "ðŸ‘¤ ÐšÐ»Ð¸ÐµÐ½Ñ‚" if msg['speaker'] == 'client' else "ðŸ’¼ ÐŸÑ€Ð¾Ð´Ð°Ð²ÐµÑ†"
        role = "user"  # Ð’ÐµÑÑŒ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ ÐºÐ°Ðº user messages Ð´Ð»Ñ AI Coach
        messages.append({
            "role": role,
            "content": f"{speaker_label}: {msg['text']}"
        })

    # Add current client message
    messages.append({
        "role": "user",
        "content": f"ðŸ‘¤ ÐšÐ»Ð¸ÐµÐ½Ñ‚: {question}"
    })

    # Call OpenRouter API
    async with httpx.AsyncClient(timeout=30.0) as client:
        response = await client.post(
            f"{openrouter_base_url}/chat/completions",
            headers={
                "Authorization": f"Bearer {openrouter_api_key}",
                "HTTP-Referer": "https://nikolaevcodev.ru",
                "X-Title": "CRM AI Voice Assistant",
            },
            json={
                "model": default_model,
                "messages": messages,
                "temperature": 0.8,  # Ð‘Ð¾Ð»ÐµÐµ ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð¿Ð¾Ð´ÑÐºÐ°Ð·ÐºÐ¸
                "max_tokens": 400,  # Ð‘Ð¾Ð»ÑŒÑˆÐµ Ð¼ÐµÑÑ‚Ð° Ð´Ð»Ñ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ð¾Ð´ÑÐºÐ°Ð·Ð¾Ðº
            }
        )

        if response.status_code != 200:
            logger.error(f"OpenRouter API error: {response.status_code} - {response.text}")
            raise Exception(f"OpenRouter API error: {response.status_code}")

        data = response.json()
        answer = data['choices'][0]['message']['content']

        logger.info(f"OpenRouter AI generated answer for category '{category}': {answer[:100]}...")
        return answer


async def generate_ai_suggestion(question: str, conversation_history: List[Dict[str, Any]]) -> str:
    """
    Generate AI-powered answer suggestion using OpenRouter API
    """
    category = categorize_question(question)

    # Try to use OpenRouter AI, fallback to knowledge base
    try:
        import httpx

        openrouter_api_key = os.getenv('OPENROUTER_API_KEY')
        if openrouter_api_key:
            # Use OpenRouter for AI-generated responses
            return await generate_ai_with_openrouter(question, conversation_history, category)
    except Exception as e:
        logger.warning(f"OpenRouter API failed, using fallback: {e}")

    # Fallback: Mock knowledge base
    knowledge_base = {
        'pricing': {
            'base_response': 'Ð¡Ñ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ð·Ð°Ð²Ð¸ÑÐ¸Ñ‚ Ð¾Ñ‚ ÐµÐ³Ð¾ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð¸ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ð¹. Ð‘Ð°Ð·Ð¾Ð²Ð°Ñ ÑÑ‚Ð°Ð²ÐºÐ° ÑÐ¾ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ 1000 Ñ€ÑƒÐ±Ð»ÐµÐ¹/Ñ‡Ð°Ñ. ÐœÑ‹ Ð¼Ð¾Ð¶ÐµÐ¼ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ Ñ‚Ð¾Ñ‡Ð½ÑƒÑŽ Ð¾Ñ†ÐµÐ½ÐºÑƒ Ð¿Ð¾ÑÐ»Ðµ Ð¾Ð±ÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ñ Ð²ÑÐµÑ… Ð´ÐµÑ‚Ð°Ð»ÐµÐ¹ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°.',
            'examples': [
                'Ð”Ð»Ñ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ð³Ð¾ Ð±Ð¾Ñ‚Ð° Ñ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¼Ð¸ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑÐ¼Ð¸ ÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð½Ð°Ñ‡Ð¸Ð½Ð°ÐµÑ‚ÑÑ Ð¾Ñ‚ 30,000 Ñ€ÑƒÐ±Ð»ÐµÐ¹',
                'Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ Ð¿Ñ€Ð¾ÐµÐºÑ‚ Ñ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸ÑÐ¼Ð¸ Ð¾Ð±Ñ…Ð¾Ð´Ð¸Ñ‚ÑÑ Ð² 50,000-100,000 Ñ€ÑƒÐ±Ð»ÐµÐ¹',
                'ÐšÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ñ AI Ð¸ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾Ð¼ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¹ - Ð¾Ñ‚ 150,000 Ñ€ÑƒÐ±Ð»ÐµÐ¹',
            ]
        },
        'timeline': {
            'base_response': 'Ð¡Ñ€Ð¾ÐºÐ¸ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð·Ð°Ð²Ð¸ÑÑÑ‚ Ð¾Ñ‚ Ð¾Ð±ÑŠÑ‘Ð¼Ð° Ð¸ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°. ÐžÐ±Ñ‹Ñ‡Ð½Ð¾:',
            'examples': [
                'ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ Ð±Ð¾Ñ‚ - 1-2 Ð½ÐµÐ´ÐµÐ»Ð¸',
                'Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ Ð¿Ñ€Ð¾ÐµÐºÑ‚ - 3-4 Ð½ÐµÐ´ÐµÐ»Ð¸',
                'Ð¡Ð»Ð¾Ð¶Ð½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° - 1.5-3 Ð¼ÐµÑÑÑ†Ð°',
                'ÐœÑ‹ Ð²ÑÐµÐ³Ð´Ð° ÑÑ‚Ð°Ñ€Ð°ÐµÐ¼ÑÑ ÑƒÐ»Ð¾Ð¶Ð¸Ñ‚ÑŒÑÑ Ð² ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð½Ñ‹Ðµ ÑÑ€Ð¾ÐºÐ¸ Ð¸ Ð´ÐµÑ€Ð¶Ð¸Ð¼ Ð²Ð°Ñ Ð² ÐºÑƒÑ€ÑÐµ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑÐ°'
            ]
        },
        'technical': {
            'base_response': 'ÐœÑ‹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¹ Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ ÑÑ‚ÐµÐº:',
            'examples': [
                'Python (aiogram, FastAPI) Ð´Ð»Ñ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð±Ð¾Ñ‚Ð¾Ð²',
                'PostgreSQL Ð´Ð»Ñ Ð½Ð°Ð´Ñ‘Ð¶Ð½Ð¾Ð³Ð¾ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð´Ð°Ð½Ð½Ñ‹Ñ…',
                'Redis Ð´Ð»Ñ ÐºÑÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¸ Ð¾Ñ‡ÐµÑ€ÐµÐ´ÐµÐ¹',
                'Docker Ð´Ð»Ñ ÐºÐ¾Ð½Ñ‚ÐµÐ¹Ð½ÐµÑ€Ð¸Ð·Ð°Ñ†Ð¸Ð¸',
                'OpenAI API Ð´Ð»Ñ AI-Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¹',
                'Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¸ Ñ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ð¼Ð¸ ÑÐµÑ€Ð²Ð¸ÑÐ°Ð¼Ð¸ Ð¿Ð¾ API'
            ]
        },
        'process': {
            'base_response': 'ÐÐ°Ñˆ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÑ‚ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ðµ ÑÑ‚Ð°Ð¿Ñ‹:',
            'examples': [
                '1. ÐžÐ±ÑÑƒÐ¶Ð´ÐµÐ½Ð¸Ðµ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð·Ð°Ð´Ð°Ð½Ð¸Ñ',
                '2. Ð¡Ð¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð¸Ð·Ð°Ð¹Ð½Ð° Ð¸ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»Ð°',
                '3. Ð Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¸ Ñ‚ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ',
                '4. Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ Ð¸ ÑÐ±Ð¾Ñ€ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾Ð¹ ÑÐ²ÑÐ·Ð¸',
                '5. Ð—Ð°Ð¿ÑƒÑÐº Ð² Ð¿Ñ€Ð¾Ð´Ð°ÐºÑˆÐ½ Ð¸ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°'
            ]
        },
        'support': {
            'base_response': 'ÐœÑ‹ Ð¿Ñ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ð»Ð½ÑƒÑŽ Ñ‚ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÑƒ:',
            'examples': [
                'ÐœÐµÑÑÑ† Ð±ÐµÑÐ¿Ð»Ð°Ñ‚Ð½Ð¾Ð¹ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ¸ Ð¿Ð¾ÑÐ»Ðµ Ð·Ð°Ð¿ÑƒÑÐºÐ°',
                'Ð‘Ñ‹ÑÑ‚Ñ€Ð¾Ðµ Ñ€ÐµÐ°Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð½Ð° ÐºÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹',
                'Ð ÐµÐ³ÑƒÐ»ÑÑ€Ð½Ñ‹Ðµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ñ Ð¸ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ',
                'Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð²Ð°ÑˆÐµÐ¹ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹'
            ]
        },
        'general': {
            'base_response': 'Ð­Ñ‚Ð¾ Ð¾Ñ‚Ð»Ð¸Ñ‡Ð½Ñ‹Ð¹ Ð²Ð¾Ð¿Ñ€Ð¾Ñ! ÐŸÐ¾Ð·Ð²Ð¾Ð»ÑŒÑ‚Ðµ Ð¿Ð¾ÑÑÐ½Ð¸Ñ‚ÑŒ:',
            'examples': [
                'ÐœÑ‹ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ÑÑ Ð½Ð° Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐµ Telegram-Ð±Ð¾Ñ‚Ð¾Ð² Ð¸ Ñ‡Ð°Ñ‚-Ð±Ð¾Ñ‚Ð¾Ð²',
                'Ð˜Ð¼ÐµÐµÐ¼ Ð¾Ð¿Ñ‹Ñ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ð¼Ð¸ Ð¾Ñ‚Ñ€Ð°ÑÐ»ÑÐ¼Ð¸ Ð¸ Ð·Ð°Ð´Ð°Ñ‡Ð°Ð¼Ð¸',
                'ÐŸÑ€ÐµÐ´Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ð¾Ð»Ð½Ñ‹Ð¹ Ñ†Ð¸ÐºÐ» Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¾Ñ‚ Ð¸Ð´ÐµÐ¸ Ð´Ð¾ Ð·Ð°Ð¿ÑƒÑÐºÐ°',
                'Ð£ Ð½Ð°Ñ Ð³Ð¸Ð±ÐºÐ¸Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ - Ð¼Ñ‹ Ð°Ð´Ð°Ð¿Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ÑÑ Ð¿Ð¾Ð´ Ð²Ð°ÑˆÐ¸ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±Ð½Ð¾ÑÑ‚Ð¸'
            ]
        }
    }

    # Get response template for category
    response_data = knowledge_base.get(category, knowledge_base['general'])
    base = response_data['base_response']
    examples = response_data['examples']

    # Construct answer
    if len(examples) > 0:
        answer = base + '\n\n' + '\n'.join([f"â€¢ {example}" for example in examples])
    else:
        answer = base

    # In production, this would be:
    # try:
    #     import openai
    #     openai.api_key = os.getenv('OPENAI_API_KEY')
    #
    #     # Build context from conversation history
    #     messages = [
    #         {"role": "system", "content": "Ð¢Ñ‹ - Ð¾Ð¿Ñ‹Ñ‚Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð½Ð¸Ðº, Ð¿Ð¾Ð¼Ð¾Ð³Ð°ÑŽÑ‰Ð¸Ð¹ Ð¾Ñ‚Ð²ÐµÑ‡Ð°Ñ‚ÑŒ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð². Ð”Ð°Ð²Ð°Ð¹ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ðµ, Ñ‚Ð¾Ñ‡Ð½Ñ‹Ðµ Ð¸ ÑƒÐ±ÐµÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹."},
    #     ]
    #
    #     # Add conversation history
    #     for msg in conversation_history[-5:]:  # Last 5 messages for context
    #         messages.append({
    #             "role": "user" if msg['speaker'] == 'client' else "assistant",
    #             "content": msg['text']
    #         })
    #
    #     # Add current question
    #     messages.append({"role": "user", "content": question})
    #
    #     # Call OpenAI
    #     response = openai.ChatCompletion.create(
    #         model="gpt-4o-mini",
    #         messages=messages,
    #         temperature=0.7,
    #         max_tokens=200
    #     )
    #
    #     answer = response.choices[0].message.content
    # except Exception as e:
    #     logger.error(f"OpenAI API error: {e}")
    #     answer = "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ð²Ð¾Ð·Ð½Ð¸ÐºÐ»Ð° Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÐµÐ¹ Ð¾Ñ‚Ð²ÐµÑ‚Ð°. ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð¾Ñ‚Ð²ÐµÑ‚ÑŒÑ‚Ðµ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÑÐ²Ð¾ÐµÐ³Ð¾ Ð¾Ð¿Ñ‹Ñ‚Ð°."

    return answer


# ====================================
# WebSocket Endpoint
# ====================================

@router.websocket("/ws/voice-assistant")
async def voice_assistant_websocket(websocket: WebSocket, auth: Optional[str] = None):
    """
    WebSocket endpoint for real-time voice assistant

    Expected message format:
    {
        "type": "speech",
        "text": "recognized speech text",
        "timestamp": "ISO timestamp",
        "speaker": "client" | "salesperson"
    }

    Response format:
    {
        "type": "suggestion",
        "question": "client question",
        "answer": "AI-generated suggestion",
        "category": "pricing|technical|timeline|process|support|general",
        "confidence": 0.85
    }
    """
    # Log connection attempt
    logger.info(f"[VOICE] WebSocket connection attempt from {websocket.client}")
    logger.info(f"[VOICE] Auth parameter: {auth[:20] if auth else 'None'}...")

    # Generate unique connection ID
    connection_id = f"conn_{datetime.now().timestamp()}"

    # Conversation history for context
    conversation_history: List[Dict[str, Any]] = []

    try:
        # Accept connection
        logger.info(f"[VOICE] Accepting WebSocket connection {connection_id}")
        await manager.connect(connection_id, websocket)
        logger.info(f"[VOICE] Connection {connection_id} accepted successfully")

        # Send welcome message
        await websocket.send_json({
            'type': 'connected',
            'message': 'AI Voice Assistant connected',
            'connection_id': connection_id,
        })
        logger.info(f"[VOICE] Welcome message sent to {connection_id}")

        while True:
            # Receive message from client
            logger.info(f"[VOICE] Waiting for message from {connection_id}...")
            data = await websocket.receive_json()
            logger.info(f"[VOICE] Received message from {connection_id}: {data}")

            message_type = data.get('type')

            if message_type == 'speech':
                text = data.get('text', '').strip()
                speaker = data.get('speaker', 'client')
                timestamp = data.get('timestamp', datetime.now().isoformat())

                logger.info(f"[VOICE] Speech message: speaker={speaker}, text='{text[:50]}'")

                if not text:
                    logger.warning(f"[VOICE] Empty text received, skipping")
                    continue

                # Add to conversation history
                conversation_history.append({
                    'text': text,
                    'speaker': speaker,
                    'timestamp': timestamp,
                })

                # Only analyze client speech
                if speaker == 'client':
                    logger.info(f"[VOICE] Analyzing client speech: '{text[:50]}'...")
                    # Analyze speech
                    analysis = await analyze_speech(text, conversation_history)
                    logger.info(f"[VOICE] Analysis result: is_question={analysis.get('is_question')}, category={analysis.get('category')}")

                    if analysis.get('is_question'):
                        logger.info(f"[VOICE] Generating AI suggestion...")
                        # Send AI suggestion
                        suggestion_data = {
                            'type': 'suggestion',
                            'question': analysis['question'],
                            'answer': analysis['suggested_answer'],
                            'category': analysis['category'],
                            'confidence': analysis.get('confidence', 0.8),
                            'timestamp': datetime.now().isoformat(),
                        }
                        await websocket.send_json(suggestion_data)
                        logger.info(f"[VOICE] AI suggestion sent: {suggestion_data['answer'][:100]}...")
                        logger.info(f"[VOICE] Question detected: {text[:50]}... -> Category: {analysis['category']}")
                    else:
                        logger.info(f"[VOICE] Not a question, skipping AI suggestion")
                else:
                    logger.info(f"[VOICE] Salesperson speech, not analyzing")

            elif message_type == 'ping':
                # Respond to ping
                await websocket.send_json({'type': 'pong'})
                logger.info(f"[VOICE] Pong sent to {connection_id}")

            elif message_type == 'clear_history':
                # Clear conversation history
                conversation_history = []
                await websocket.send_json({
                    'type': 'history_cleared',
                    'message': 'Conversation history cleared',
                })
                logger.info(f"[VOICE] History cleared for {connection_id}")

    except WebSocketDisconnect:
        manager.disconnect(connection_id)
        logger.info(f"[VOICE] Client {connection_id} disconnected")

    except Exception as e:
        logger.error(f"[VOICE] WebSocket error for {connection_id}: {e}", exc_info=True)
        manager.disconnect(connection_id)
        try:
            await websocket.send_json({
                'type': 'error',
                'message': f'Server error: {str(e)}',
            })
        except:
            pass


# ====================================
# REST Endpoints (optional, for testing)
# ====================================

@router.get("/voice-assistant/status")
async def get_voice_assistant_status():
    """Get voice assistant service status"""
    return {
        'status': 'operational',
        'active_connections': len(manager.active_connections),
        'timestamp': datetime.now().isoformat(),
    }


@router.post("/voice-assistant/test-analyze")
async def test_analyze(text: str):
    """Test speech analysis (for debugging)"""
    result = await analyze_speech(text, [])
    return JSONResponse(content=result)
